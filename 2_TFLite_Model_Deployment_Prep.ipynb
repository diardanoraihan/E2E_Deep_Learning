{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Lite\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Introduction</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will cover about:\n",
    "- what TFLite is,\n",
    "- How it works to bring a Machine Learning model to mobile and embedded system,\n",
    "- How to shrink the model to fit these devices,\n",
    "- the overall architecture that support TFLite,\n",
    "- How to use the model to iOS, android, and embedded system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Make the model available on a resource constraint hardware like mobile edge__\n",
    "\n",
    "After you created the best model that is ready to be deployed, we need to think about all the things that a mobile solution needs. TensorFlow Lite helps you create and build the model with ease for mobile / edge computing devices and offer them to the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lightweight__. Our aim is to be lightweight working on small low-power devices like phone and may not be as accurate as those which run on super computer in the cloud.\n",
    "\n",
    "__Low-latency__. TensorFlow Lite is suitable to run on devices with low-latency, even without internet connection.\n",
    "\n",
    "__Privacy__. TensorFlow Lite uses on devices machine learning to operate, so no need for the data to leave the device ensuring privacy. \n",
    "\n",
    "__Improved power consumption__. TFLite improves power consumption since network connection tends to be power hungry. \n",
    "\n",
    "__Efficient model format__. TFLite creates a small binary-sized model with the minor impact on accuracy.\n",
    "\n",
    "__Pre-trained models__. TFLite has many pre-trained models for most common machine learning tasks with some example we can try to see how it runs on mobile device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow Lite consists of two main components: __Converter__ and __Interpreter__.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style='text-align:center'>CONVERTER (to TensorFlow Lite Format)</th>\n",
    "        <th style='text-align:center'>INTERPRETER (Core)</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style='text-align:center'>Transform TensorFlow models into a form efficient for reading by the interpreter.</th>\n",
    "        <th style='text-align:center'>Diverse platform support (Android, iOS, embedded Linux, microcontrollers/IoT)</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style='text-align:center'>Introduces optimizations to improve binary size model performance and/or reduce model size.</th>\n",
    "        <th style='text-align:center'>Platform APIs for accelerated inference.</th>\n",
    "    </tr>\n",
    "    \n",
    "</table>\n",
    "\n",
    "To put it all together, here are the steps to utilize the TensorFlow Lite for our benefit:\n",
    "\n",
    "__1. Jump Start__. Use the Pretrained or Retrained Models\n",
    "\n",
    "__2. Custom Model__. Develop and deploy a custom model.\n",
    "\n",
    "__3. Performance__. Explore options, validate and accelerate models.\n",
    "\n",
    "__4. Optimize__. Model Optimization Toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running inference on computer having machine learning on mobile devices is __resource demanding__, due to devices limited processing and power. So inference in these devices need to be performed quickly in order to avoid overheat and make mostly real-time application possible. \n",
    "\n",
    "<img src='Visualization/performance.jpg' alt='taken from tfcertification.com' width=\"500\">\n",
    "\n",
    "For this purpose, TensorFlow Lite can use hardware acceleration libraries / APIs for supported devices. One way to improve inference on Android devices, you can use Android Neural Network API for optimization.\n",
    "\n",
    "Then, you can also leverage hardware like edge TPU to boost the inference. Edge TPUs are solely build for operating on deep learning models. Not only for serving them, but training them as well. Hence, they are known for high performing and have a low-power footprint while being small in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delegates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow Lite Delegates is another form of acceleration from TensorFlow Lite. It is a way to pass your graph execution to hardware that is specialized to run inference. For this, TensorFlow Lite provides code for an experimental GPU delegate that can be used to accelerate the models on devices that have an available GPU. __GPUs are built to run many mathematical operation in parallel which makes them perfect for machine learning inference.__\n",
    "\n",
    "<img src='visualization/delegates.jpg' alt='taken from tfcertification.com' width=\"600\">\n",
    "\n",
    "We recommend you to check the following link to see the sample apps that use the TensorFlow Lite Delegates:\n",
    "https://www.tensorflow.org/lite/performance/gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the generally limited resources on mobile and mobile devices, so it's very critical that deployed machine learning models have optimum model size, low latency and power consumption. Thus, there are several methods to achieve this optimum optimization:\n",
    "\n",
    "1. __Quantization.__ It reduces the precition of the numbers in the weights of the models.\n",
    "2. __Weight Pruning.__ It reduces the overall number parameters.\n",
    "3. __Model Topology Transforms.__ It converts the overall model topology to get more efficient model. \n",
    "\n",
    "For now, we recommend you to focus only on Quantization because that can give you the biggest and easiest gains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Quantize?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Quantization__ is the process of constraining the input from a continuous or otherwise a large set of values (such as the real numbers) to a discrete set (such as integers). Quantization optimizes your model with reduces precition representation of weights and optionally activation for both storage and computation. The followings are several benefits we can gain from Quantization:\n",
    "1. All available CPU platforms are supported.\n",
    "2. Reducing latency and inference cost.\n",
    "3. Low memory footprint.\n",
    "4. Allow execution on hardware restricted-to or optimized-for fixed-point operations.\n",
    "5. Optimized models for special purpose HW accelerators (TPUs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. JUMP START__. Use pretrained or Retrained Models.\n",
    "\n",
    "__2. CUSTOM MODEL__. Develop and deploy a custom model.\n",
    "\n",
    "__3. PERFORMANCE__. Explore options, validate and accelerate models.\n",
    "\n",
    "__4. Optimize__. Model Optimization Toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>How To [Part 1]</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Lite Converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the process will look something like this:\n",
    "\n",
    "<img src='visualization/tflite_summary.jpg' alt='taken from tfcertification.com' width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will train the model using TensorFlow then save it as the saved model.\n",
    "- Next, we will use TFLite converter to convert the saved model into a TFLite model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Visualization/tflite converter.jpg' alt='taken from tfcertification.com' width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you create a model with TensorFlow, you can save the model either using:\n",
    "- `tf.Keras` Model\n",
    "- `SavedModel`\n",
    "- Concrete Function(s)\n",
    "\n",
    "Then, the converter will take the model and convert it to __`.tflite`__ format, which a flat buffer that can be used on a mobile device, along with optional backend like NN API or GPUs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='visualization/parameters for conversion.jpg' alt='taken from tfcertification.com' width='800'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Phyton, when we develop a work station, we can call __`tf.lite.TFLiteConverter`__ to the conversion. Depending on how your model is represented, you can then instantiate it from SavedModel / Keras Model / Concrete Function(s) in order to get the output.\n",
    "\n",
    "__Preferred Model: `SavedModel`__\n",
    "- The standard for serializing a TensorFlow model\n",
    "- A MetaGraph to hold metadata\n",
    "- Holds snapshot of the trained model (with model weights and computation)\n",
    "- No model building code required\n",
    "- Support model versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert TensorFlow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load the `.h5` model that you have trained__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load the best saved model from our last training\n",
    "myModel = load_model('Models/model_4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Instantiate the TFLite converter from that saved model__. \n",
    "\n",
    "Once you have done, simply call the convert method and you will get the flattened version that you can use with TensorFlow Lite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a TFLiteConverter object from a TensorFlow Keras model \n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(myModel)\n",
    "\n",
    "# converts a Keras model based on instance variable\n",
    "myModel_tflite = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Save out the `.tflite` file by writing it to the file system__. \n",
    "\n",
    "We can write the byte of the converter TFLite model to the file system. Now you have a model that can be deployed to Android, iOS, or edge system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Save the model\n",
    "tflite_model_file = Path('clothing_classifier.tflite')\n",
    "tflite_model_file.write_bytes(myModel_tflite)\n",
    "\n",
    "# with tf.io.gfile.GFile('clothing_classifier.tflite', mode='wb') as file:\n",
    "#     file.write(myModel_tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-training Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple method to do the quantization is called post-training quantization. In this case, instead of quantizing your model during training, and effectively changing your training code, you instead quantize as part of the process of converting the model to the TensorFlow Lite format. To put it simply, we convert all the floats in the weight of the models to integer.\n",
    "\n",
    "The followings are the benefits of using this technique:\n",
    "- Reduced precision representation with 3x lower latency\n",
    "- Little degradation in model accuracy\n",
    "- Optimization modes: `default` (both size and latency), `size` (being reduced) , `latency` (being reduced).\n",
    "- Efficiently represents an arbitrary magnitude of ranges\n",
    "- Quantization target speficication (FP32/INT8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the example of how we overwrite the default behavior of the converter to optimize primarily for size, latency, or leave it at the default where the converter will try to figure out the best balance for size and latency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "myModel = load_model('Models/model_4.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(myModel)\n",
    "\n",
    "# Optimize for size\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "\n",
    "# Optimize for latency\n",
    "# converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
    "\n",
    "# Optimize for the best balance between size and latency\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Training Integer Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='visualization/integer-quantization.jpg' alt='taken from tfcertification.com' width=\"600\">\n",
    "\n",
    "At some cases, like Edge TPUs, the accelerator uses only integer. For this, the optimization toolkit allows you to do the post-training integer quantization that makes the model 4 times smaller. You can further optimize by using __calibration data__ when you run inference on the small set of input so as to determine the right scaling parameters to use when converting a model for integer quantization.\n",
    "\n",
    "The following is how to convert a saved model to TensorFlow Lite with post-training integer quantization.\n",
    "- Define the generator which is designed to generate samples from the datasets\n",
    "- Set the default optimization mode where balance the size and latency\n",
    "- Pass our generator to TensorFlow Lite Converter as a representative dataset. The representative dataset is used for evaluating optimization. This is done by running multiple inferences on floating point TensorFlow Lite Model using the used representative dataset as input. \n",
    "- We use the values from inferences to determine the scaling parameters needed to execute all tensors of the model in integer arithmetic. This makes the model allow the activations to be quantized along with the weight.\n",
    "- The resulting model will have as many quantized operations as possible. For operations that don't have a quantized implementation, they will fall back to the float one, hence allowing the model to still take float inputs and outputs for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Define the generator\n",
    "def generator():\n",
    "    data = tfds.load(...)\n",
    "    for _ in range(num_calibration_steps):\n",
    "        image, = data.take(1)\n",
    "        yield [image]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "\n",
    "# Set the optimization mode\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Pass the representative dataset to the converter\n",
    "converter.representative_dataset = tf.lite.RepresentativeDataset(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have operations that don't quantize implementation, their floating point values will be used automatically. This makes for convergent to occur smoothly, while restricting deployment to special purpose accelerators that only support integers. Hence, to support these devices that don't support floating point operation, we just tell the converter to only output integers, and this can be done by constraining the quantization target specifications to `TFLITE_BUILTINS_INT8`.\n",
    "\n",
    "Learn more about supported ops: https://www.tensorflow.org/lite/guide/ops_compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "# Set the optimization mode\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
    "\n",
    "# Pass the representative dataset to the converter\n",
    "converter.representative_dataset = tf.lite.RepresentativeDataset(generator)\n",
    "\n",
    "# Restricting supported target op specification to INT8\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome the unsupported ops, we can use __`TF-SELECT`__:\n",
    "\n",
    "http://www.tensorflow.org/lite/guide/ops_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "\n",
    "converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, \n",
    "                        tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the Models in Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the flow chart that we're likely to follow when optimizing the TensorFlow Lite models. \n",
    "<img src='visualization/optimization summary.jpg' alt='taken from tfcertification.com' width=\"800\">\n",
    "\n",
    "If you don't intend to quantize the model, you will end up with the floating point model. However, if you only want to quantize the weight in the model, you can do so by just setting the one of the post-training optimization models in the converter. The converter will do its best to quantize all the operation but your model may still end up with few floating point operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Lite Interpreter in Python\n",
    "\n",
    "One really nice feature is to test your model using Python. You don't need to deploy it on mobile or embedded system before you can start using it. \n",
    "\n",
    "In short, the followings are the steps we can go:\n",
    "- Load the TensorFlow Lite Model and allocate the tensors\n",
    "- Extract the input and output tensors for the model\n",
    "- Set the input tensor with some validation data and invoke the interpreter to run inference on it before reading the result by looking at the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite\n",
    "\n",
    "# Load the TFLite model and allocate the tensors\n",
    "interpreter = tflite.Interpreter(model_content = tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Point the data to be used for testing and run the interpreter\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>How to [Part 2]</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a Basic Model Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='visualization/getstarted.jpg' alt='taken from tfcertification.com' width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='visualization/transferlearning.jpg' alt='taken from tfcertification.com' width=\"600\">\n",
    "A common scenario when using mobile application is to take the existing models that have been on large datasets with many trained layers that are specialized to your task. Then, you can take advantage of this by retraining a few last layers using features that were learned in the original model and still get a great result even with small dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning with TensorFlow Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we want to classify cats and dogs, here is the steps we can follow:\n",
    "\n",
    "<img src='visualization/tfhub.jpg' alt='taken from tfcertification.com' width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "__Notes__:\n",
    "- Typically, we will not put this procedure in production.\n",
    "- TensorFlow based on Python is too large and not optimized for serving/prediction. However, it's optimized for training. Hence, we need to use something else for production.\n",
    "- Instead, we can use TensorFlow Serving, TensorFlow Lite, AWS Lambda, etc.\n",
    "\n",
    "__AWS Lambda__:\n",
    "\n",
    "By using AWS Lambda, we can run code without thinking about the servers. Hence, we don't need to rent an instance, instead just define a function and specify what is the input and output. We only need to pay for the time this function is actually run. For example, if our function only needs 2 seconds to run, then we only need to pay for 2 seconds. \n",
    "\n",
    "Now, we want to use this model and deploy it using Lambda. Here are the steps you can follow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Diardano Raihan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\DIARDA~1\\AppData\\Local\\Temp\\tmpuz_ckke6\\assets\n"
     ]
    }
   ],
   "source": [
    "# load the best saved model from our last training\n",
    "myModel = load_model('Models/model_4.h5')\n",
    "\n",
    "# create a TFLiteConverter object from a TensorFlow Keras model \n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(myModel)\n",
    "\n",
    "# converts a Keras model based on instance variable\n",
    "myModel_tflite = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190051464"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Save the model\n",
    "tflite_model_file = Path('clothing_classifier.tflite')\n",
    "tflite_model_file.write_bytes(myModel_tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFLite Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite\n",
    "# in AWS Lambda, we need to use this import below\n",
    "# import tflite_runtime.interpreter as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interpreter interface for any model in TFLite\n",
    "interpreter = tflite.Interpreter(model_path='clothing_classifier.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'input_1',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 150, 150,   3]),\n",
       "  'shape_signature': array([ -1, 150, 150,   3]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of input details from the model\n",
    "input_details = interpreter.get_input_details()\n",
    "input_index = input_details[0]['index']\n",
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Identity',\n",
       "  'index': 237,\n",
       "  'shape': array([ 1, 10]),\n",
       "  'shape_signature': array([-1, 10]),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of output details from the model\n",
    "output_details = interpreter.get_output_details()\n",
    "output_index = output_details[0]['index']\n",
    "output_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Test Image as Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'short',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\n",
    "    0: 'dress',\n",
    "    1: 'hat',\n",
    "    2: 'longsleeve',\n",
    "    3: 'outwear',\n",
    "    4: 'pants',\n",
    "    5: 'shirt',\n",
    "    6: 'shoes',\n",
    "    7: 'short',\n",
    "    8: 'skirt',\n",
    "    9: 't-shirt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=150x150 at 0x2B16B8B5308>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "\n",
    "# Obtain the image location\n",
    "img_loc = 'datasets/test/hat/2a12baab-f020-42e3-8e6b-5d82e3ed0b55.jpg'\n",
    "\n",
    "# load the image using load_img module\n",
    "img = load_img(path=img_loc, target_size=(150,150))\n",
    "\n",
    "# Turn the image into a 4D-array\n",
    "X = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Normalize the image\n",
    "X = X/255.0\n",
    "\n",
    "# Turn the image into a Numpy array with float32 data type\n",
    "X = X.astype('float32')\n",
    "print(X.dtype)\n",
    "\n",
    "# Check the image\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the value of the input tensor\n",
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the value of the output tensor\n",
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': 4.2887897e-31,\n",
       " 'hat': 1.0,\n",
       " 'longsleeve': 1.780517e-16,\n",
       " 'outwear': 1.9622327e-24,\n",
       " 'pants': 2.201639e-33,\n",
       " 'shirt': 4.8804883e-26,\n",
       " 'shoes': 4.4479933e-18,\n",
       " 'short': 3.290352e-37,\n",
       " 'skirt': 9.4776506e-36,\n",
       " 't-shirt': 1.0133569e-28}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(labels, preds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hat'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict.get(np.argmax(preds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite\n",
    "# in AWS Lambda, we need to use this import below\n",
    "# import tflite_runtime.interpreter as tflite\n",
    "\n",
    "# Create an interpreter interface for any model in TFLite\n",
    "interpreter = tflite.Interpreter(model_path='clothing_classifier.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get a list of input details from the model\n",
    "input_details = interpreter.get_input_details()\n",
    "input_index = input_details[0]['index']\n",
    "\n",
    "# Get a list of output details from the model\n",
    "output_details = interpreter.get_output_details()\n",
    "output_index = output_details[0]['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func: `predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    # set the value of the input tensor\n",
    "    interpreter.set_tensor(input_index, X)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get the value of the output tensor\n",
    "    preds = interpreter.get_tensor(output_index)\n",
    "    \n",
    "    return preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func: `decode_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'short',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]\n",
    "\n",
    "def decode_predictions(pred):\n",
    "    result = {label: float(score) for label, score in zip(labels, pred)}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func: `preprocessor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(img_url):\n",
    "    # load the image using PIL module\n",
    "    img = Image.open(urlopen(img_url))\n",
    "    \n",
    "    # Specify the image target size\n",
    "    img = img.resize((150, 150))\n",
    "    \n",
    "    # Turn the image into a 4D-array\n",
    "    X = np.expand_dims(img, axis =0)\n",
    "    \n",
    "    # Normalize the image\n",
    "    X = X/255.0\n",
    "    \n",
    "    # Turn the image into a Numpy array with float32 data type\n",
    "    X = X.astype('float32')\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func: `lambda_handler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # Obtain the image location\n",
    "    url = event['url']\n",
    "    \n",
    "    # Preprocess the image\n",
    "    X = preprocessor(url)\n",
    "    \n",
    "    # Make prediction\n",
    "    preds = predict(X)\n",
    "    \n",
    "    # Obtain the result\n",
    "    results = decode_predictions(preds)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the event (trigger)\n",
    "event = {'url': 'https://raw.githubusercontent.com/diardanoraihan/E2E_Deep_Learning/main/Clothes_Classification/Datasets/test/pants/01033304-f9a4-48c4-af65-677512880fae.jpg'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the lambda_handler\n",
    "results = lambda_handler(event, context=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': 2.1086591459607007e-06,\n",
       " 'hat': 2.0010727829530145e-13,\n",
       " 'longsleeve': 0.0012293169274926186,\n",
       " 'outwear': 0.000773618754465133,\n",
       " 'pants': 0.3927960991859436,\n",
       " 'shirt': 0.00033335198531858623,\n",
       " 'shoes': 5.916072609579714e-07,\n",
       " 'short': 0.6048617362976074,\n",
       " 'skirt': 3.102071332250489e-06,\n",
       " 't-shirt': 1.20492529731564e-07}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the prediction result\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Locally with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compile everything as a separate file called `lambda_fucntion.py`. Then, we want to take and deploy it using AWS Lambda. For that, we will use Docker. AWS Lambda supports docker, so we can use a container image to deploy our function.\n",
    "\n",
    "In this section, you will learn how to run the model locally using Docker within your machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `lambda_function.py`\n",
    "\n",
    "First, let's create a file that stores all the functions needed to run the app, starting from defining the interpreter, receiving the input image, preprocessing the image, and use the saved model to make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in AWS Lambda, we need to use this import below\n",
    "import tflite_runtime.interpreter as tflite\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "\n",
    "# Create an interpreter interface for any model in TFLite\n",
    "interpreter = tflite.Interpreter(model_path='clothing_classifier.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get a list of input details from the model\n",
    "input_details = interpreter.get_input_details()\n",
    "input_index = input_details[0]['index']\n",
    "\n",
    "# Get a list of output details from the model\n",
    "output_details = interpreter.get_output_details()\n",
    "output_index = output_details[0]['index']\n",
    "\n",
    "def predict(X):\n",
    "    # set the value of the input tensor\n",
    "    interpreter.set_tensor(input_index, X)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get the value of the output tensor\n",
    "    preds = interpreter.get_tensor(output_index)\n",
    "    \n",
    "    return preds[0]\n",
    "\n",
    "labels = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'short',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]\n",
    "\n",
    "def decode_predictions(pred):\n",
    "    result = {label: float(score) for label, score in zip(labels, pred)}\n",
    "    return result\n",
    "\n",
    "def preprocessor(img_url):\n",
    "    # load the image using PIL module\n",
    "    img = Image.open(urlopen(img_url))\n",
    "    \n",
    "    # Specify the image target size\n",
    "    img = img.resize((150, 150))\n",
    "    \n",
    "    # Turn the image into a 4D-array\n",
    "    X = np.expand_dims(img, axis =0)\n",
    "    \n",
    "    # Normalize the image\n",
    "    X = X/255.0\n",
    "    \n",
    "    # Turn the image into a Numpy array with float32 data type\n",
    "    X = X.astype('float32')\n",
    "    \n",
    "    return X\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    # Obtain the image location\n",
    "    url = event['url']\n",
    "    \n",
    "    # Preprocess the image\n",
    "    X = preprocessor(url)\n",
    "    \n",
    "    # Make prediction\n",
    "    preds = predict(X)\n",
    "    \n",
    "    # Obtain the result\n",
    "    results = decode_predictions(preds)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Dockerfile`\n",
    "\n",
    "The next step is to create a Dockerfile. __What should we put in the docker file?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Dockerfile__ is a way for you to put all the dependencies you need for running the code into one single image that contains everything. \n",
    "\n",
    "\n",
    "- __A Docker image__ is a private file system just for your container. It provides all the files and code your container needs.\n",
    "\n",
    "\n",
    "- This image is self-sufficient because it has everything you need, such as:\n",
    "    - installing the python package management system.\n",
    "    - installing the pillow library to deal with image file.\n",
    "    - installing the TensorFlow Lite tflite_runtime interpreter.\n",
    "    - taking our model in tflite file and copy it to the docker image.\n",
    "    - taking the lambda_function.py and copy it to the docker image.\n",
    "    \n",
    "The file below is the official docker image from Amazon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "```python\n",
    "FROM public.ecr.aws/lambda/python:3.7\n",
    "\n",
    "RUN pip3 install --upgrade pip\n",
    "\n",
    "RUN pip3 install pillow --no-cache-dir\n",
    "RUN pip3 install https://raw.githubusercontent.com/alexeygrigorev/serverless-deep-learning/master/tflite/tflite_runtime-2.2.0-cp37-cp37m-linux_x86_64.whl --no-cache-dir\n",
    "\n",
    "COPY clothing_classifier.tflite clothing_classifier.tflite\n",
    "COPY lambda_function.py lambda_function.py\n",
    "\n",
    "CMD [ \"lambda_function.lambda_handler\" ]\n",
    "```\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we need to do now is to run and build this docker image, and deploy it using AWS. Another option to deploy the model is by running it locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followings are the steps we do to run the application locally:\n",
    "\n",
    "__Run the docker daemon__. There are 2 ways to do this: \n",
    "- First option is to open __cmd__ as __administrator__, then launch the following command: `\"C:\\Program Files\\Docker\\Docker\\DockerCli.exe\" -SwitchDaemon`\n",
    "    \n",
    "- Second option is to run the __Docker Desktop__ from the start menu and validate that the docker is in __running__ state. \n",
    "    \n",
    "\n",
    "__Build an image from a Dockerfile__. _A Docker image_ is a private file system just for your container. It provides all the files and code your container needs.One important note is that do not change the working directory in Dockerfile\n",
    "\n",
    "```\n",
    "$ docker build -t tf-lite-lambda .\n",
    "```\n",
    "\n",
    "- The command above will build the image from the content of the folder you are currently in, with the tag name `tf-lite-lambda`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Container Image\n",
    "\n",
    "__Start a container based on the image you built in the previous step__. Running a container launches your application with private resources, securely isolated from the rest of your machine.\n",
    "\n",
    "```\n",
    "$ docker run --rm -p 8080:8080 --name clothes-classifier tf-lite-lambda\n",
    "```\n",
    "\n",
    "- The `-p` (stands for _publish_) indicates that we want to map the container port 80 to the host machine port 80. The container opens a Web server on port 80, and we can map ports on our computer to ports exposed by the container.\n",
    "\n",
    "- The `--rm` (stands for _remove_) indicates that we want to automatically remove the cotainer when it exists.\n",
    "\n",
    "- The `--name` gives a name to a new container, and `tf-lite-lambda` is the image name we use to create the container.\n",
    "\n",
    "__Save and share your image on Docker Hub__ to enable other users to easily download and run the image on any destination machine.\n",
    "\n",
    "```\n",
    "$ docker tag tf-lite-lambda [userName]/tf-lite-lambda\n",
    "$ docker push [userName]/tf-lite-lambda\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the screenshots of the results from the previous commands:\n",
    "\n",
    "<img src='visualization/build n run the docker app.jpg' alt='taken from tfcertification.com'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `test.py`\n",
    "\n",
    "After we run the model, we want to test it. We need to create a special file that we can call to see the results of what the model has predicted. \n",
    "\n",
    "The file contains:\n",
    "- the complete categories from the expected input image.\n",
    "- a PANTS (test) image obtained from this link: http://bit.ly/mlbookcamp-pants. We will send a request that has a key `url` and a url of the image\n",
    "- a URL address indicating that we deploy on the localhost inside the docker.\n",
    "- a procedure to send a post request to the target URL address to obtain the prediction result.\n",
    "- parsing the prediction result and showing it to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "labels = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'short',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]\n",
    "\n",
    "data = {\n",
    "    \"url\": \"http://bit.ly/mlbookcamp-pants\"\n",
    "}\n",
    "\n",
    "url =\"http://localhost:8080/2015-03-31/functions/function/invocations\"\n",
    "\n",
    "results = requests.post(url, json=data).json()\n",
    "\n",
    "print('[PREDICTION RESULT]')\n",
    "print('+-------------------------------------------+')\n",
    "score = []\n",
    "for cat in results:\n",
    "\tprint('+ {}: {}'.format(cat, results[cat]))\n",
    "\tscore.append(results[cat])\n",
    "\n",
    "best_cat = np.argmax(score)\n",
    "print('+-------------------------------------------+')\n",
    "print('Therefore, the model predicts the input image as {}'.format(labels[best_cat].upper()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `test.py` in your CLI and see the result for yourself:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src='visualization/app prediction result.jpg' alt='taken from tfcertification.com'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy on AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just deployed the model locally with Docker. Now, we can bring the same container and deploy it on AWS. AWS has everything you need to deploy your deep learning model online. For this case, we will use AWS CLI, AWS ECR, AWS Lambda, and AWS API Gateaway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install AWS CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything you do with AWS is an API call. Although you can do by visiting the website, but wouldn't it be nice if you can do it one time? Hence, make sure you have installed AWS CLI in your local machine. https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-windows.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Your AWS Account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to deploy the app on AWS, it's obvious we need to set up an account there. After you make an AWS IAM User account, set up your Access Key ID, Secret Access Key, Default Region, and Default Output Format (commonly JSON). Once we have done this, we can make programmatic calls to AWS from the AWS CLI.\n",
    "\n",
    "```\n",
    "$ aws configure\n",
    "```\n",
    "\n",
    "<img src='visualization/aws configure.jpg' alt='taken from tfcertification.com'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Repo in AWS ECR (Elastic Container Registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS ECR is a place for us to put Docker images. By running the following command, we will create a private repository to store the Docker image we have built previously.\n",
    "\n",
    "```\n",
    "$ aws ecr create-repository --repository-name lambda-images\n",
    "```\n",
    "\n",
    "<img src='visualization/aws create repo.jpg' alt='taken from tfcertification.com'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish the Image to the Repo\n",
    "\n",
    "Now, we want to publish the image that we have built locally. The followings are the steps cited directly from AWS (`AWS ECR > Repositories > lambda-images > View Push Command`):\n",
    "\n",
    "- Retrieve an authentication token and authenticate your Docker client to your registry.\n",
    "\n",
    "```\n",
    "$ aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin XXXXXXXXX474.dkr.ecr.us-east-1.amazonaws.com\n",
    "```\n",
    "\n",
    "- Build your Docker image using the following command. \n",
    "\n",
    "```\n",
    "$ docker build -t lambda-images .\n",
    "```\n",
    "\n",
    "- Tag your image so you can push the image to this repository.\n",
    "\n",
    "```\n",
    "$ docker tag tf-lite-lambda XXXXXXXXX474.dkr.ecr.us-east-1.amazonaws.com/lambda-images:tf-lite-lambda\n",
    "```\n",
    "\n",
    "- Run the following command to push this image to your newly created AWS repository.\n",
    "\n",
    "```\n",
    "$ docker push XXXXXXXXX474.dkr.ecr.us-east-1.amazonaws.com/lambda-images:tf-lite-lambda\n",
    "```\n",
    "\n",
    "Check the pushed image on the AWS ECR web page. Make sure to copy the URL because we need it to create a Lambda Function.\n",
    "\n",
    "<img src='visualization/aws push image.jpg' alt='taken from tfcertification.com' width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lambda Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to create a Lambda Function. Go to AWS `Lambda` and click `Create function`. Choose `Container Image`.\n",
    "\n",
    "<img src='visualization/aws create lambda func.jpg' alt='taken from tfcertification.com' width=\"800\">\n",
    "\n",
    "Give your function a unique name and fill in the Container Image URL with the Image URL that you copied earlier. By leaving everything to default, click `Create function`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Lambda Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just created a lambda function for a prediction task. However, the current configuration does not give us sufficient memory and timeout. We have a big model and the function will take some time to run and load everything to the memory for the first time. Thus, we need to reconfigure it. Go to `Configuration` > `General Configuration` > click `Edit` and set RAM and Timeout to __512/1024__ and __30__ sec respectively. Save it.\n",
    "\n",
    "<img src='visualization/aws RAM Timeout.jpg' alt='taken from tfcertification.com' width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a test with this JSON file format:\n",
    "```python\n",
    "{\n",
    "    \"url\": \"https://tinyurl.com/clothes-t-shirt\"\n",
    "}\n",
    "```\n",
    "<img src='visualization/aws test event.jpg' alt='taken from tfcertification.com' width=\"800\">\n",
    "\n",
    "Give a new event a name and click `Test` after you save it. Then, you will see the following result:\n",
    "\n",
    "<img src='visualization/aws test result.jpg' alt='taken from tfcertification.com' width=\"800\">\n",
    "\n",
    "One thing you need to be aware of is that with AWS Lambda, you will be charged based on the number of requests and the duration, that is, the time it takes for our code to be executed. Please refer to this [link](https://aws.amazon.com/lambda/pricing/) for more pricing info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Gateaway Integration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just tested the function and it seems to work well in making the prediction. What's left is to use it from outside (online). To do this, we need to create an API via AWS API Gateaway.\n",
    "\n",
    "__1. Create a New API__\n",
    "\n",
    "- Visit AWS API Gateaway, then choose REST API by clicking `Build` button.\n",
    "- Choose the protocol: `REST`. Choose New API for __Creating New API__. Then, fill in the API Name and add some description.\n",
    "\n",
    "<img src='visualization/aws rest api.jpg' alt='taken from tfcertification.com' width=\"300\"><img src='visualization/aws api setting.jpg' alt='taken from tfcertification.com' width=\"600\">\n",
    "\n",
    "__2. Create a resource: Predict and a method POST__\n",
    "- From `Actions`, choose Make Resource > fill in \"predict\".\n",
    "- From `Actions`, choose Make Method > select `POST`\n",
    "<img src='visualization/aws method resource.jpg' alt='taken from tfcertification.com' width=\"200\">\n",
    "\n",
    "__3. Select the Lambda Function and add some details__. \n",
    "- Click on `POST`, then make sure to write the correct name for the __Lambda Function__ and leave everything by default. \n",
    "<img src='visualization/aws predict post setup.jpg' width=\"500\">\n",
    "\n",
    "__4. Test the API__. \n",
    "- From the flow chart execution, click `Test`.\n",
    "<img src='visualization/aws test api.jpg' width=\"800\">\n",
    "- To test it, input the following code in the __Request Body__:\n",
    "<img src='visualization/aws request body.jpg' width=\"400\">\n",
    "- You should see the following result in the __Response Body__:\n",
    "<img src='visualization/aws response body.jpg' width=\"400\">\n",
    "\n",
    "__5. Deploy the API__\n",
    "- Finally, we need to deploy the API to use it outside. From `Actions`, click `DEPLOY API`. \n",
    "<img src='visualization/aws deploy api.jpg' width=\"400\">\n",
    "- Obtain the URL from the \"Invoke URL\" section. In this case, we have: https://xw2bv0y8mb.execute-api.us-east-1.amazonaws.com/test\n",
    "- Open the Postman App or go to [reqbin](https://reqbin.com/) to test the REST API we just created. Notice, since we specify `predict` as our method for `POST`, we need to add `/predict` at the end of the URL. Hence, the complete URL to make an API call for making a prediction is `https://xw2bv0y8mb.execute-api.us-east-1.amazonaws.com/test/predict`. Copy and paste the link to the URL section in the app.\n",
    "- Copy the following object in JSON as the body to make this POST request. Click `Send`.\n",
    "```javascript\n",
    "{\n",
    "    \"url\": \"https://tinyurl.com/clothes-t-shirt\"\n",
    "}\n",
    "```\n",
    "- You can see the prediction result as the content received after making the API call POST request. Congrats, now your deep learning model is totally online and ready to help the world become a better place!\n",
    "\n",
    "<img src='visualization/aws post request.jpg'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
